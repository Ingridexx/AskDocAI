# CompareDocAI (Backend) â€” Q&A sobre documentaÃ§Ã£o com RAG

API backend para perguntas e respostas sobre **documentaÃ§Ãµes** (PDF/TXT/MD) usando **RAG**:
- **IngestÃ£o** â†’ chunking â†’ **FAISS** (vetores)
- **Busca semÃ¢ntica** (com **MMR** opcional)
- **GeraÃ§Ã£o** com **Gemini** (Google)
- **MÃºltiplas coleÃ§Ãµes** com upload e **reindex em background**

> Foco deste repo: **backend**. Um frontend em React pode consumir esta API (CORS habilitado).

---

## âœ¨ Features
- **ColeÃ§Ãµes**: separe bases por tema (`/collections`, `/{name}/upload`)
- **RAG** com fontes (arquivo e pÃ¡gina)
- **MMR** para diversificar resultados
- **ReindexaÃ§Ã£o em background** apÃ³s upload
- **CORS** liberado p/ front
- **Swagger** em `/docs` e health em `/health`

---

## ğŸ§° Stack
- **Python 3.11+**
- **FastAPI** + Uvicorn
- **LangChain** + **FAISS**
- **Gemini** (Google) â€” `text-embedding-004` e `gemini-2.5-flash`

---

## ğŸ—ï¸ Arquitetura (VisÃ£o RÃ¡pida)

```mermaid
flowchart LR
A[Cliente / Front] -->|POST /ask| B(FastAPI)
B -->|collection| C[IndexManager]
C -->|load()| D[(FAISS por coleÃ§Ã£o)]
B -->|retrieve docs| D
B -->|make prompt (contexto+history)| E[Gemini (LLM)]
E -->|answer+citations| B --> A

subgraph IngestÃ£o
U[POST /collections/{name}/upload] --> V{Background}
V --> W[load docs + chunk]
W --> X[FAISS.from_documents]
X --> Y[save index (faiss_index)]
Y --> C
end
